{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:00:21.198154Z",
          "iopub.execute_input": "2024-04-27T12:00:21.198699Z",
          "iopub.status.idle": "2024-04-27T12:00:35.797911Z",
          "shell.execute_reply.started": "2024-04-27T12:00:21.19866Z",
          "shell.execute_reply": "2024-04-27T12:00:35.796814Z"
        },
        "trusted": true,
        "id": "dLJBw_Dx5KPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify whether a CUDA-enabled GPU is available\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA-enabled GPU found. Training should be faster.')\n",
        "else:\n",
        "    print('No GPU found. Training will be carried out on CPU, which might be '\n",
        "          'slower.\\n\\nIf running on Google Colab, you can request a GPU runtime by'\n",
        "          ' clicking\\n`Runtime/Change runtime type` in the top bar menu, then '\n",
        "          'selecting \\'GPU\\'\\nunder \\'Hardware accelerator\\'.')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:00:40.0833Z",
          "iopub.execute_input": "2024-04-27T12:00:40.084181Z",
          "iopub.status.idle": "2024-04-27T12:00:45.781402Z",
          "shell.execute_reply.started": "2024-04-27T12:00:40.084147Z",
          "shell.execute_reply": "2024-04-27T12:00:45.780276Z"
        },
        "trusted": true,
        "id": "I-3bWDUz5KPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for colab\n",
        "!pip install mne\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install pandas"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:00:49.737863Z",
          "iopub.execute_input": "2024-04-27T12:00:49.73833Z",
          "iopub.status.idle": "2024-04-27T12:01:50.932063Z",
          "shell.execute_reply.started": "2024-04-27T12:00:49.738302Z",
          "shell.execute_reply": "2024-04-27T12:01:50.930966Z"
        },
        "trusted": true,
        "id": "zrq7MQjG5KPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import general modules\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:02:05.495108Z",
          "iopub.execute_input": "2024-04-27T12:02:05.495994Z",
          "iopub.status.idle": "2024-04-27T12:02:05.911486Z",
          "shell.execute_reply.started": "2024-04-27T12:02:05.495961Z",
          "shell.execute_reply": "2024-04-27T12:02:05.910813Z"
        },
        "trusted": true,
        "id": "cxh4f4Ci5KPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:02:09.305558Z",
          "iopub.execute_input": "2024-04-27T12:02:09.306674Z",
          "iopub.status.idle": "2024-04-27T12:02:09.311399Z",
          "shell.execute_reply.started": "2024-04-27T12:02:09.306639Z",
          "shell.execute_reply": "2024-04-27T12:02:09.310506Z"
        },
        "trusted": true,
        "id": "sS2UWQBt5KPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "4exAigU35KPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne.datasets.sleep_physionet.age import fetch_data\n",
        "\n",
        "mne.set_log_level('ERROR')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:02:13.257491Z",
          "iopub.execute_input": "2024-04-27T12:02:13.257939Z",
          "iopub.status.idle": "2024-04-27T12:02:15.505429Z",
          "shell.execute_reply.started": "2024-04-27T12:02:13.257902Z",
          "shell.execute_reply": "2024-04-27T12:02:15.504617Z"
        },
        "trusted": true,
        "id": "jUW2wq8K5KPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = range(80)\n",
        "recordings = [1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:02:31.388824Z",
          "iopub.execute_input": "2024-04-27T12:02:31.389351Z",
          "iopub.status.idle": "2024-04-27T12:02:31.393875Z",
          "shell.execute_reply.started": "2024-04-27T12:02:31.389324Z",
          "shell.execute_reply": "2024-04-27T12:02:31.392935Z"
        },
        "trusted": true,
        "id": "-OSelLWP5KPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = fetch_data(subjects=subjects, recording=recordings, on_missing='warn')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T12:02:38.187329Z",
          "iopub.execute_input": "2024-04-27T12:02:38.187745Z",
          "iopub.status.idle": "2024-04-27T14:30:26.063466Z",
          "shell.execute_reply.started": "2024-04-27T12:02:38.187712Z",
          "shell.execute_reply": "2024-04-27T14:30:26.062609Z"
        },
        "trusted": true,
        "id": "iWjMHTQD5KPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sleep_physionet_raw(raw_fname, annot_fname, load_eeg_only=True, crop_wake_mins=30):\n",
        "\n",
        "    mapping = {'EOG horizontal': 'eog',\n",
        "               'Resp oro-nasal': 'misc',\n",
        "               'EMG submental': 'misc',\n",
        "               'Temp rectal': 'misc',\n",
        "               'Event marker': 'misc'}\n",
        "    exclude = mapping.keys() if load_eeg_only else ()\n",
        "\n",
        "    raw = mne.io.read_raw_edf(raw_fname, exclude=exclude)\n",
        "    annots = mne.read_annotations(annot_fname)\n",
        "    raw.set_annotations(annots, emit_warning=False)\n",
        "    if not load_eeg_only:\n",
        "        raw.set_channel_types(mapping)\n",
        "\n",
        "    if crop_wake_mins > 0:  # Cut start and end Wake periods\n",
        "        # Find first and last sleep stages\n",
        "        mask = [x[-1] in ['1', '2', '3', '4', 'R'] for x in annots.description]\n",
        "        sleep_event_inds = np.where(mask)[0]\n",
        "\n",
        "        # Crop raw with adjusted tmax\n",
        "        tmin_candidate = annots[int(sleep_event_inds[0])]['onset'] - crop_wake_mins * 60\n",
        "        tmin = max(tmin_candidate, 0)\n",
        "        tmax = min(raw.times[-1], 86399.99)  # Choose a valid tmax value\n",
        "        raw.crop(tmin=tmin, tmax=tmax)\n",
        "\n",
        "    # Rename EEG channels\n",
        "    ch_names = {i: i.replace('EEG ', '') for i in raw.ch_names if 'EEG' in i}\n",
        "    mne.rename_channels(raw.info, ch_names)\n",
        "\n",
        "    # Save subject and recording information in raw.info\n",
        "    basename = os.path.basename(raw_fname)\n",
        "    subj_nb, rec_nb = int(basename[3:5]), int(basename[5])\n",
        "    raw.info['subject_info'] = {'id': subj_nb, 'rec_id': rec_nb}\n",
        "\n",
        "    return raw"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:34:00.372001Z",
          "iopub.execute_input": "2024-04-27T14:34:00.372775Z",
          "iopub.status.idle": "2024-04-27T14:34:00.383798Z",
          "shell.execute_reply.started": "2024-04-27T14:34:00.372742Z",
          "shell.execute_reply": "2024-04-27T14:34:00.382587Z"
        },
        "trusted": true,
        "id": "gbsuV7pa5KPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load recordings\n",
        "raws = [load_sleep_physionet_raw(f[0], f[1]) for f in fnames]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:34:04.438616Z",
          "iopub.execute_input": "2024-04-27T14:34:04.439244Z",
          "iopub.status.idle": "2024-04-27T14:34:22.541944Z",
          "shell.execute_reply.started": "2024-04-27T14:34:04.439212Z",
          "shell.execute_reply": "2024-04-27T14:34:22.541099Z"
        },
        "trusted": true,
        "id": "O_0ou66x5KPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a recording as a sanity check\n",
        "raws[0].plot();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:35:16.723527Z",
          "iopub.execute_input": "2024-04-27T14:35:16.724277Z",
          "iopub.status.idle": "2024-04-27T14:35:17.889717Z",
          "shell.execute_reply.started": "2024-04-27T14:35:16.724245Z",
          "shell.execute_reply": "2024-04-27T14:35:17.888806Z"
        },
        "trusted": true,
        "id": "I9GMMfR65KPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing raw data"
      ],
      "metadata": {
        "id": "VHx2RCzm5KPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l_freq, h_freq = None, 30\n",
        "\n",
        "for raw in raws:\n",
        "    raw.load_data().filter(l_freq, h_freq)  # filtering happens in-place"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:35:25.642636Z",
          "iopub.execute_input": "2024-04-27T14:35:25.643354Z",
          "iopub.status.idle": "2024-04-27T14:39:25.556716Z",
          "shell.execute_reply.started": "2024-04-27T14:35:25.643326Z",
          "shell.execute_reply": "2024-04-27T14:39:25.555855Z"
        },
        "trusted": true,
        "id": "qXsr_xGn5KPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the power spectrum of a recording as sanity check\n",
        "raws[0].plot_psd();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:39:47.626697Z",
          "iopub.execute_input": "2024-04-27T14:39:47.627588Z",
          "iopub.status.idle": "2024-04-27T14:39:48.572507Z",
          "shell.execute_reply.started": "2024-04-27T14:39:47.627547Z",
          "shell.execute_reply": "2024-04-27T14:39:48.57148Z"
        },
        "trusted": true,
        "id": "raNtCRTv5KPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_epochs(raw, chunk_duration=30.):\n",
        "\n",
        "    annotation_desc_2_event_id = {\n",
        "        'Sleep stage W': 1,\n",
        "        'Sleep stage 1': 2,\n",
        "        'Sleep stage 2': 3,\n",
        "        'Sleep stage 3': 4,\n",
        "        'Sleep stage 4': 4,\n",
        "        'Sleep stage R': 5}\n",
        "\n",
        "    events, _ = mne.events_from_annotations(\n",
        "        raw, event_id=annotation_desc_2_event_id,\n",
        "        chunk_duration=chunk_duration)\n",
        "\n",
        "    # create a new event_id that unifies stages 3 and 4\n",
        "    event_id = {\n",
        "        'Sleep stage W': 1,\n",
        "        'Sleep stage 1': 2,\n",
        "        'Sleep stage 2': 3,\n",
        "        'Sleep stage 3/4': 4,\n",
        "        'Sleep stage R': 5}\n",
        "\n",
        "    tmax = 30. - 1. / raw.info['sfreq']  # tmax in included\n",
        "    picks = mne.pick_types(raw.info, eeg=True, eog=True)\n",
        "    epochs = mne.Epochs(raw=raw, events=events, picks=picks, preload=True,\n",
        "                         tmin=0., tmax=tmax, baseline=None)\n",
        "\n",
        "    return epochs.get_data(), epochs.events[:, 2] - 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:40:40.202853Z",
          "iopub.execute_input": "2024-04-27T14:40:40.203918Z",
          "iopub.status.idle": "2024-04-27T14:40:40.21119Z",
          "shell.execute_reply.started": "2024-04-27T14:40:40.203884Z",
          "shell.execute_reply": "2024-04-27T14:40:40.210304Z"
        },
        "trusted": true,
        "id": "S0xHn2SW5KPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "\n",
        "\n",
        "class EpochsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, epochs_data, epochs_labels, subj_nb=None,\n",
        "                 rec_nb=None, transform=None):\n",
        "        assert len(epochs_data) == len(epochs_labels)\n",
        "        self.epochs_data = epochs_data\n",
        "        self.epochs_labels = epochs_labels\n",
        "        self.subj_nb = subj_nb\n",
        "        self.rec_nb = rec_nb\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.epochs_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X, y = self.epochs_data[idx], self.epochs_labels[idx]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        X = torch.as_tensor(X[None, ...])\n",
        "        return X, y\n",
        "\n",
        "\n",
        "def scale(X):\n",
        "\n",
        "    X -= np.mean(X, axis=1, keepdims=True)\n",
        "    return X / np.std(X, axis=1, keepdims=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:40:44.517287Z",
          "iopub.execute_input": "2024-04-27T14:40:44.518296Z",
          "iopub.status.idle": "2024-04-27T14:40:44.526122Z",
          "shell.execute_reply.started": "2024-04-27T14:40:44.518261Z",
          "shell.execute_reply": "2024-04-27T14:40:44.52526Z"
        },
        "trusted": true,
        "id": "R5nB1wDp5KPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply windowing and move to pytorch dataset\n",
        "all_datasets = [EpochsDataset(*extract_epochs(raw), subj_nb=raw.info['subject_info']['id'],\n",
        "                              rec_nb=raw.info['subject_info']['rec_id'], transform=scale)\n",
        "                for raw in raws]\n",
        "\n",
        "# Concatenate into a single dataset\n",
        "dataset = ConcatDataset(all_datasets)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:42:17.172499Z",
          "iopub.execute_input": "2024-04-27T14:42:17.172889Z",
          "iopub.status.idle": "2024-04-27T14:48:28.293196Z",
          "shell.execute_reply.started": "2024-04-27T14:42:17.17286Z",
          "shell.execute_reply": "2024-04-27T14:48:28.292357Z"
        },
        "trusted": true,
        "id": "1Olisul35KPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making train, valid and test splits"
      ],
      "metadata": {
        "id": "L-Sp8DlV5KPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeavePGroupsOut\n",
        "\n",
        "\n",
        "def pick_recordings(dataset, subj_rec_nbs):\n",
        "\n",
        "    pick_idx = list()\n",
        "    for subj_nb, rec_nb in subj_rec_nbs:\n",
        "        for i, ds in enumerate(dataset.datasets):\n",
        "            if (ds.subj_nb == subj_nb) and (ds.rec_nb == rec_nb):\n",
        "                pick_idx.append(i)\n",
        "\n",
        "    remaining_idx = np.setdiff1d(\n",
        "        range(len(dataset.datasets)), pick_idx)\n",
        "\n",
        "    pick_ds = ConcatDataset([dataset.datasets[i] for i in pick_idx])\n",
        "    if len(remaining_idx) > 0:\n",
        "        remaining_ds = ConcatDataset(\n",
        "            [dataset.datasets[i] for i in remaining_idx])\n",
        "    else:\n",
        "        remaining_ds = None\n",
        "\n",
        "    return pick_ds, remaining_ds\n",
        "\n",
        "\n",
        "def train_test_split(dataset, n_groups, split_by='subj_nb'):\n",
        "\n",
        "    groups = [getattr(ds, split_by) for ds in dataset.datasets]\n",
        "    train_idx, test_idx = next(\n",
        "        LeavePGroupsOut(n_groups).split(X=groups, groups=groups))\n",
        "\n",
        "    train_ds = ConcatDataset([dataset.datasets[i] for i in train_idx])\n",
        "    test_ds = ConcatDataset([dataset.datasets[i] for i in test_idx])\n",
        "\n",
        "    return train_ds, test_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:55:06.499609Z",
          "iopub.execute_input": "2024-04-27T14:55:06.500308Z",
          "iopub.status.idle": "2024-04-27T14:55:06.721052Z",
          "shell.execute_reply.started": "2024-04-27T14:55:06.500277Z",
          "shell.execute_reply": "2024-04-27T14:55:06.720334Z"
        },
        "trusted": true,
        "id": "gucvshmm5KPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We seed the random number generators to make our splits reproducible\n",
        "torch.manual_seed(87)\n",
        "np.random.seed(87)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:55:11.785279Z",
          "iopub.execute_input": "2024-04-27T14:55:11.786241Z",
          "iopub.status.idle": "2024-04-27T14:55:11.802978Z",
          "shell.execute_reply.started": "2024-04-27T14:55:11.786206Z",
          "shell.execute_reply": "2024-04-27T14:55:11.802168Z"
        },
        "trusted": true,
        "id": "xZWmr4Xd5KPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use recording 1 of subjects 0-9 as test set\n",
        "test_recs = [(subj_nb, rec_nb)  # DO NOT CHANGE! This is a fixed set.\n",
        "             for subj_nb, rec_nb in zip(range(10), [1] * 10)]\n",
        "test_ds, train_ds = pick_recordings(dataset, test_recs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:55:21.829235Z",
          "iopub.execute_input": "2024-04-27T14:55:21.829917Z",
          "iopub.status.idle": "2024-04-27T14:55:21.835485Z",
          "shell.execute_reply.started": "2024-04-27T14:55:21.82988Z",
          "shell.execute_reply": "2024-04-27T14:55:21.834488Z"
        },
        "trusted": true,
        "id": "KRUMdl7r5KPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split remaining recordings into training and validation sets\n",
        "n_subjects_valid = max(1, int(len(train_ds.datasets) * 0.2))\n",
        "train_ds, valid_ds = train_test_split(train_ds, n_subjects_valid, split_by='subj_nb')\n",
        "\n",
        "print('Number of examples in each set:')\n",
        "print(f'Training: {len(train_ds)}')\n",
        "print(f'Validation: {len(valid_ds)}')\n",
        "print(f'Test: {len(test_ds)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:55:28.771515Z",
          "iopub.execute_input": "2024-04-27T14:55:28.771897Z",
          "iopub.status.idle": "2024-04-27T14:55:28.780047Z",
          "shell.execute_reply.started": "2024-04-27T14:55:28.771868Z",
          "shell.execute_reply": "2024-04-27T14:55:28.778933Z"
        },
        "trusted": true,
        "id": "-GPCDu-i5KPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n",
        "y_train = pd.Series([y for _, y in train_ds]).map(classes_mapping)\n",
        "ax = y_train.value_counts().plot(kind='barh')\n",
        "ax.set_xlabel('Number of training examples');\n",
        "ax.set_ylabel('Sleep stage');\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:55:35.027693Z",
          "iopub.execute_input": "2024-04-27T14:55:35.028107Z",
          "iopub.status.idle": "2024-04-27T14:55:45.796374Z",
          "shell.execute_reply.started": "2024-04-27T14:55:35.02808Z",
          "shell.execute_reply": "2024-04-27T14:55:45.795491Z"
        },
        "trusted": true,
        "id": "Nt1jip665KPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n",
        "y_test = pd.Series([y for _, y in test_ds]).map(classes_mapping)\n",
        "ax = y_test.value_counts().plot(kind='barh')\n",
        "ax.set_xlabel('Number of testing examples');\n",
        "ax.set_ylabel('Sleep stage');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:55:56.484552Z",
          "iopub.execute_input": "2024-04-27T14:55:56.484881Z",
          "iopub.status.idle": "2024-04-27T14:55:58.769568Z",
          "shell.execute_reply.started": "2024-04-27T14:55:56.484857Z",
          "shell.execute_reply": "2024-04-27T14:55:58.76867Z"
        },
        "trusted": true,
        "id": "tq3twKdq5KPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n",
        "y_valid = pd.Series([y for _, y in valid_ds]).map(classes_mapping)\n",
        "ax = y_valid.value_counts().plot(kind='barh')\n",
        "ax.set_xlabel('Number of validating examples');\n",
        "ax.set_ylabel('Sleep stage');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:56:03.001553Z",
          "iopub.execute_input": "2024-04-27T14:56:03.001886Z",
          "iopub.status.idle": "2024-04-27T14:56:05.567293Z",
          "shell.execute_reply.started": "2024-04-27T14:56:03.001862Z",
          "shell.execute_reply": "2024-04-27T14:56:05.566413Z"
        },
        "trusted": true,
        "id": "CL1rdBhR5KPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing class weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "train_y = np.concatenate([ds.epochs_labels for ds in train_ds.datasets])\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
        "print(class_weights)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:56:10.73266Z",
          "iopub.execute_input": "2024-04-27T14:56:10.733514Z",
          "iopub.status.idle": "2024-04-27T14:56:10.775304Z",
          "shell.execute_reply.started": "2024-04-27T14:56:10.733484Z",
          "shell.execute_reply": "2024-04-27T14:56:10.774309Z"
        },
        "trusted": true,
        "id": "qRDwv5mS5KPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the neural network"
      ],
      "metadata": {
        "id": "_3FCbgiB5KPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class ImprovedSleepStager(nn.Module):\n",
        "    def __init__(self, n_channels, sfreq, n_conv_chs=16, time_conv_size_s=1.0,\n",
        "                 max_pool_size_s=0.25, n_classes=5, input_size_s=30,\n",
        "                 dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        time_conv_size = int(time_conv_size_s * sfreq)\n",
        "        max_pool_size = int(max_pool_size_s * sfreq)\n",
        "        input_size = int(input_size_s * sfreq)\n",
        "        pad_size = time_conv_size // 2\n",
        "        self.n_channels = n_channels\n",
        "\n",
        "        if n_channels > 1:\n",
        "            self.spatial_conv = nn.Conv2d(1, n_channels, (n_channels, 1))\n",
        "            self.batch_norm_spatial = nn.BatchNorm2d(n_channels)\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n",
        "            nn.LeakyReLU(0.2),  # Leaky ReLU activation\n",
        "            nn.BatchNorm2d(n_conv_chs),  # Batch Normalization\n",
        "            nn.MaxPool2d((1, max_pool_size)),\n",
        "            nn.Conv2d(n_conv_chs, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm2d(n_conv_chs),\n",
        "            nn.MaxPool2d((1, max_pool_size))\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(self._len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs), n_classes)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
        "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.n_channels > 1:\n",
        "            x = self.spatial_conv(x)\n",
        "            x = self.batch_norm_spatial(x)\n",
        "            x = x.transpose(1, 2)\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        return self.fc(x.flatten(start_dim=1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:56:15.379782Z",
          "iopub.execute_input": "2024-04-27T14:56:15.380521Z",
          "iopub.status.idle": "2024-04-27T14:56:15.3925Z",
          "shell.execute_reply.started": "2024-04-27T14:56:15.380474Z",
          "shell.execute_reply": "2024-04-27T14:56:15.391627Z"
        },
        "trusted": true,
        "id": "ry9kH-ua5KPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfreq = raws[0].info['sfreq']  # Sampling frequency\n",
        "n_channels = raws[0].info['nchan']  # Number of channels\n",
        "\n",
        "model = ImprovedSleepStager(n_channels, sfreq, n_classes=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T14:57:15.178547Z",
          "iopub.execute_input": "2024-04-27T14:57:15.17894Z",
          "iopub.status.idle": "2024-04-27T14:57:15.187367Z",
          "shell.execute_reply.started": "2024-04-27T14:57:15.178913Z",
          "shell.execute_reply": "2024-04-27T14:57:15.1862Z"
        },
        "trusted": true,
        "id": "c3-so2Kx5KPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:17:52.933603Z",
          "iopub.execute_input": "2024-04-27T15:17:52.934395Z",
          "iopub.status.idle": "2024-04-27T15:18:05.538268Z",
          "shell.execute_reply.started": "2024-04-27T15:17:52.934366Z",
          "shell.execute_reply": "2024-04-27T15:18:05.536925Z"
        },
        "trusted": true,
        "id": "mZfh2G4b5KPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Using device \\'{device}\\'.')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:07:20.358593Z",
          "iopub.execute_input": "2024-04-27T15:07:20.359629Z",
          "iopub.status.idle": "2024-04-27T15:07:20.642915Z",
          "shell.execute_reply.started": "2024-04-27T15:07:20.359586Z",
          "shell.execute_reply": "2024-04-27T15:07:20.642071Z"
        },
        "trusted": true,
        "id": "GqHlIu3m5KPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(\"Total parameters in the model: \", total_params)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:25:46.179091Z",
          "iopub.execute_input": "2024-04-27T15:25:46.179518Z",
          "iopub.status.idle": "2024-04-27T15:25:46.18611Z",
          "shell.execute_reply.started": "2024-04-27T15:25:46.179488Z",
          "shell.execute_reply": "2024-04-27T15:25:46.185178Z"
        },
        "trusted": true,
        "id": "fgolnqEX5KPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and monitor network"
      ],
      "metadata": {
        "id": "STXnC9-B5KPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create dataloaders\n",
        "train_batch_size = 56 # Important hyperparameter\n",
        "valid_batch_size = 256  # Can be made as large as what fits in memory; won't impact performance\n",
        "num_workers = 0  # Number of processes to use for the data loading process; 0 is the main Python process\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    train_ds, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\n",
        "loader_valid = DataLoader(\n",
        "    valid_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n",
        "loader_test = DataLoader(\n",
        "    test_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:08:01.539099Z",
          "iopub.execute_input": "2024-04-27T15:08:01.539924Z",
          "iopub.status.idle": "2024-04-27T15:08:01.545833Z",
          "shell.execute_reply.started": "2024-04-27T15:08:01.539895Z",
          "shell.execute_reply": "2024-04-27T15:08:01.544953Z"
        },
        "trusted": true,
        "id": "5Qq0dybQ5KPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
        "\n",
        "def _do_train(model, loader, optimizer, criterion, device, metric):\n",
        "    # training loop\n",
        "    model.train()\n",
        "\n",
        "    train_loss = np.zeros(len(loader))\n",
        "    y_pred_all, y_true_all = list(), list()\n",
        "    for idx_batch, (batch_x, batch_y) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "        batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "        y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "        train_loss[idx_batch] = loss.item()\n",
        "\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    perf = metric(y_true, y_pred)\n",
        "\n",
        "    return np.mean(train_loss), perf\n",
        "\n",
        "\n",
        "def _validate(model, loader, criterion, device, metric):\n",
        "    # validation loop\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = np.zeros(len(loader))\n",
        "    y_pred_all, y_true_all = list(), list()\n",
        "    with torch.no_grad():\n",
        "        for idx_batch, (batch_x, batch_y) in enumerate(loader):\n",
        "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "            output = model.forward(batch_x)\n",
        "\n",
        "            loss = criterion(output, batch_y)\n",
        "            val_loss[idx_batch] = loss.item()\n",
        "\n",
        "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "            y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    perf = metric(y_true, y_pred)\n",
        "\n",
        "    return np.mean(val_loss), perf\n",
        "\n",
        "\n",
        "def train(model, loader_train, loader_valid, optimizer, criterion, n_epochs,\n",
        "          patience, device, metric=None):\n",
        "\n",
        "    best_valid_loss = np.inf\n",
        "    best_model = copy.deepcopy(model)\n",
        "    waiting = 0\n",
        "    history = list()\n",
        "\n",
        "    if metric is None:\n",
        "        metric = balanced_accuracy_score\n",
        "\n",
        "    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf')\n",
        "    print('-------------------------------------------------------------------')\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_loss, train_perf = _do_train(\n",
        "            model, loader_train, optimizer, criterion, device, metric=metric)\n",
        "        valid_loss, valid_perf = _validate(\n",
        "            model, loader_valid, criterion, device, metric=metric)\n",
        "        history.append(\n",
        "            {'epoch': epoch,\n",
        "             'train_loss': train_loss, 'valid_loss': valid_loss,\n",
        "             'train_perf': train_perf, 'valid_perf': valid_perf})\n",
        "\n",
        "        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n",
        "              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}')\n",
        "\n",
        "        # model saving\n",
        "        if valid_loss < best_valid_loss:\n",
        "            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n",
        "            best_valid_loss = valid_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            waiting = 0\n",
        "        else:\n",
        "            waiting += 1\n",
        "\n",
        "        # model early stopping\n",
        "        if waiting >= patience:\n",
        "            print(f'Stop training at epoch {epoch}')\n",
        "            print(f'Best val loss : {best_valid_loss:.4f}')\n",
        "            break\n",
        "\n",
        "    return best_model, history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:08:01.759625Z",
          "iopub.execute_input": "2024-04-27T15:08:01.760271Z",
          "iopub.status.idle": "2024-04-27T15:08:01.778392Z",
          "shell.execute_reply.started": "2024-04-27T15:08:01.760245Z",
          "shell.execute_reply": "2024-04-27T15:08:01.777497Z"
        },
        "trusted": true,
        "id": "tU-CCq6k5KPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=0)\n",
        "criterion = CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:08:04.528903Z",
          "iopub.execute_input": "2024-04-27T15:08:04.52982Z",
          "iopub.status.idle": "2024-04-27T15:08:08.718255Z",
          "shell.execute_reply.started": "2024-04-27T15:08:04.529787Z",
          "shell.execute_reply": "2024-04-27T15:08:08.717457Z"
        },
        "trusted": true,
        "id": "93eT64cH5KPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "patience = 6\n",
        "\n",
        "best_model, history = train(\n",
        "    model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience,\n",
        "    device, metric=cohen_kappa_score)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:08:32.896194Z",
          "iopub.execute_input": "2024-04-27T15:08:32.896747Z",
          "iopub.status.idle": "2024-04-27T15:15:21.337545Z",
          "shell.execute_reply.started": "2024-04-27T15:08:32.896718Z",
          "shell.execute_reply": "2024-04-27T15:15:21.336599Z"
        },
        "trusted": true,
        "id": "qvPNH0iy5KPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the learning curves\n",
        "\n",
        "history_df = pd.DataFrame(history)\n",
        "ax1 = history_df.plot(x='epoch', y=['train_loss', 'valid_loss'], marker='o')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2 = history_df.plot(x='epoch', y=['train_perf', 'valid_perf'], marker='o')\n",
        "ax2.set_ylabel('Cohen\\'s kappa')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:15:38.613563Z",
          "iopub.execute_input": "2024-04-27T15:15:38.613958Z",
          "iopub.status.idle": "2024-04-27T15:15:39.121548Z",
          "shell.execute_reply.started": "2024-04-27T15:15:38.613932Z",
          "shell.execute_reply": "2024-04-27T15:15:39.120614Z"
        },
        "trusted": true,
        "id": "k6PwmH3i5KPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute test performance\n",
        "\n",
        "best_model.eval()\n",
        "\n",
        "y_pred_all, y_true_all = list(), list()\n",
        "for batch_x, batch_y in loader_test:\n",
        "    batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "    batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "    output = model.forward(batch_x)\n",
        "    y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "    y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred = np.concatenate(y_pred_all)\n",
        "y_true = np.concatenate(y_true_all)\n",
        "rec_ids = np.concatenate(  # indicates which recording each example comes from\n",
        "    [[i] * len(ds) for i, ds in enumerate(test_ds.datasets)])\n",
        "\n",
        "test_bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "test_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "\n",
        "print(f'Test balanced accuracy: {test_bal_acc:0.3f}')\n",
        "print(f'Test Cohen\\'s kappa: {test_kappa:0.3f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:15:46.743293Z",
          "iopub.execute_input": "2024-04-27T15:15:46.744215Z",
          "iopub.status.idle": "2024-04-27T15:15:50.250943Z",
          "shell.execute_reply.started": "2024-04-27T15:15:46.744185Z",
          "shell.execute_reply": "2024-04-27T15:15:50.249962Z"
        },
        "trusted": true,
        "id": "G5YSQhis5KPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing results"
      ],
      "metadata": {
        "id": "KszhJglc5KPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(conf_mat, classes_mapping):\n",
        "    ticks = list(classes_mapping.keys())\n",
        "    tick_labels = classes_mapping.values()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    im = ax.imshow(conf_mat, cmap='Reds')\n",
        "\n",
        "    ax.set_yticks(ticks)\n",
        "    ax.set_yticklabels(tick_labels)\n",
        "    ax.set_xticks(ticks)\n",
        "    ax.set_xticklabels(tick_labels)\n",
        "    ax.set_ylabel('True label')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    ax.set_title('Confusion matrix')\n",
        "\n",
        "    for i in range(len(ticks)):\n",
        "        for j in range(len(ticks)):\n",
        "            text = ax.text(\n",
        "                j, i, conf_mat[i, j], ha='center', va='center', color='k')\n",
        "\n",
        "    fig.colorbar(im, ax=ax, fraction=0.05, label='# examples')\n",
        "    fig.tight_layout()\n",
        "\n",
        "    return fig, ax"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:57:51.185458Z",
          "iopub.execute_input": "2024-04-27T15:57:51.186217Z",
          "iopub.status.idle": "2024-04-27T15:57:51.194974Z",
          "shell.execute_reply.started": "2024-04-27T15:57:51.186183Z",
          "shell.execute_reply": "2024-04-27T15:57:51.194019Z"
        },
        "trusted": true,
        "id": "RyRByLrp5KPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(conf_mat, classes_mapping);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:57:56.450894Z",
          "iopub.execute_input": "2024-04-27T15:57:56.452019Z",
          "iopub.status.idle": "2024-04-27T15:57:56.808366Z",
          "shell.execute_reply.started": "2024-04-27T15:57:56.451984Z",
          "shell.execute_reply": "2024-04-27T15:57:56.807449Z"
        },
        "trusted": true,
        "id": "4IIGR6a35KPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model.eval()\n",
        "\n",
        "y_pred_all, y_true_all = list(), list()\n",
        "for batch_x, batch_y in loader_test:\n",
        "    batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "    batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "    output = model.forward(batch_x)\n",
        "    y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "    y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred = np.concatenate(y_pred_all)\n",
        "y_true = np.concatenate(y_true_all)\n",
        "\n",
        "# Compute precision, recall, F1-score, and support for each class\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_true, y_pred, labels=np.unique(y_true), average=None)\n",
        "\n",
        "# Display the results for each class\n",
        "for class_label, p, r, f, s in zip(np.unique(y_true), precision, recall, f1_score, support):\n",
        "    print(f'Class {class_label}:')\n",
        "    print(f'  Precision: {p:.3f}')\n",
        "    print(f'  Recall: {r:.3f}')\n",
        "    print(f'  F1-score: {f:.3f}')\n",
        "    print(f'  Support: {s}')\n",
        "    print('-----------------------')\n",
        "\n",
        "# Display overall metrics\n",
        "precision_macro, recall_macro, f1_score_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "print('Overall Metrics:')\n",
        "print(f'  Macro Precision: {precision_macro:.3f}')\n",
        "print(f'  Macro Recall: {recall_macro:.3f}')\n",
        "print(f'  Macro F1-score: {f1_score_macro:.3f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:58:01.600512Z",
          "iopub.execute_input": "2024-04-27T15:58:01.601215Z",
          "iopub.status.idle": "2024-04-27T15:58:05.259234Z",
          "shell.execute_reply.started": "2024-04-27T15:58:01.601186Z",
          "shell.execute_reply": "2024-04-27T15:58:05.258156Z"
        },
        "trusted": true,
        "id": "gSAoMYjX5KPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model.eval()\n",
        "\n",
        "y_pred_all, y_true_all = list(), list()\n",
        "for batch_x, batch_y in loader_test:\n",
        "    batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "    batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "    output = model.forward(batch_x)\n",
        "    y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "    y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred = np.concatenate(y_pred_all)\n",
        "y_true = np.concatenate(y_true_all)\n",
        "\n",
        "# Compute precision, recall, F1-score, and confusion matrix for each class\n",
        "precision, recall, f1_score, support = precision_recall_fscore_support(y_true, y_pred, labels=np.unique(y_true), average=None)\n",
        "conf_mat = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Class': np.unique(y_true),\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1-score': f1_score,\n",
        "    'Support': support\n",
        "})\n",
        "\n",
        "# Display the confusion matrix and metrics DataFrame\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_mat)\n",
        "print(\"\\nMetrics:\")\n",
        "print(metrics_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:58:10.82702Z",
          "iopub.execute_input": "2024-04-27T15:58:10.827466Z",
          "iopub.status.idle": "2024-04-27T15:58:14.293831Z",
          "shell.execute_reply.started": "2024-04-27T15:58:10.827412Z",
          "shell.execute_reply": "2024-04-27T15:58:14.292907Z"
        },
        "trusted": true,
        "id": "4KO427zF5KPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model.eval()\n",
        "\n",
        "y_pred_all, y_true_all = list(), list()\n",
        "for batch_x, batch_y in loader_test:\n",
        "    batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "    batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "    output = model.forward(batch_x)\n",
        "    y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "    y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred = np.concatenate(y_pred_all)\n",
        "y_true = np.concatenate(y_true_all)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate specificity for each class\n",
        "specificity = []\n",
        "for i in range(conf_mat.shape[0]):\n",
        "    TN = np.sum(conf_mat) - np.sum(conf_mat[i, :]) - np.sum(conf_mat[:, i]) + conf_mat[i, i]\n",
        "    FP = np.sum(conf_mat[:, i]) - conf_mat[i, i]\n",
        "    specificity.append(TN / (TN + FP))\n",
        "\n",
        "# Display specificity for each class\n",
        "for i, spec in enumerate(specificity):\n",
        "    print(f\"Specificity for class {i}: {spec:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:58:19.84201Z",
          "iopub.execute_input": "2024-04-27T15:58:19.842869Z",
          "iopub.status.idle": "2024-04-27T15:58:23.320919Z",
          "shell.execute_reply.started": "2024-04-27T15:58:19.842835Z",
          "shell.execute_reply": "2024-04-27T15:58:23.319984Z"
        },
        "trusted": true,
        "id": "pXQVzSwg5KPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot hypnogram for one recording\n",
        "\n",
        "mask = rec_ids == 0  # pick a recording number\n",
        "\n",
        "t = np.arange(len(y_true[mask])) * 30 / 3600\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "ax.plot(t, y_true[mask], label='True')\n",
        "ax.plot(t, y_pred[mask], alpha=0.7, label='Predicted')\n",
        "ax.set_yticks([0, 1, 2, 3, 4])\n",
        "ax.set_yticklabels(['W', 'N1', 'N2', 'N3', 'R'])\n",
        "ax.set_xlabel('Time (h)')\n",
        "ax.set_title('Hypnogram')\n",
        "ax.legend();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-27T15:58:30.252372Z",
          "iopub.execute_input": "2024-04-27T15:58:30.253268Z",
          "iopub.status.idle": "2024-04-27T15:58:30.527625Z",
          "shell.execute_reply.started": "2024-04-27T15:58:30.253235Z",
          "shell.execute_reply": "2024-04-27T15:58:30.526642Z"
        },
        "trusted": true,
        "id": "_4r4cuSl5KPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}